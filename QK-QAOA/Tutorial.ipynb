{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from argparse import Namespace\n",
    "import exp_L2L "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define model \n",
    "    Args:\n",
    "        model_type (str): the model type. LSTM, QKLSTM, QKLSTM, or FWP\n",
    "        mapping_type (str): the mapping model type, Linear (FC) or ID\n",
    "        layers [int]: the number of layers for LSTM, QKLSTM, QLSTM or FWP\n",
    "        input_feature_dim [int]: the number of params for LSTM output to QAOA ansatz\n",
    "        max_total_params [int]: the max numbers for QAOA we need for this experiment\n",
    "        loss_function_type (str): the loss function type, weighted or observed improvement (define by Verdon's papaer)\n",
    "        qaoa_layers [int]: the number of QAOA layers for ansatz\n",
    "        lr_sequence [float]: learning rate for LSTM, QKLSTM, QLSTM or FWP\n",
    "        lr_mapping [float]: learning rate for mapping model\n",
    "        epochs [int]: the number of training epochs\n",
    "        steps_recurrent_loop_train [int]: the number of recurrent step for training\n",
    "        conv_tol_sequence [float]: the convergence tolerance for training\n",
    "        Model_save_path (str): the path to save model's parameters\n",
    "        train_set: the training dataset\n",
    "        val_set: the validation dataset\n",
    "        time_out [int]: the time out for training (in seconds)\n",
    "        continue_train [bool]: whether continue training from existing model\n",
    "        load_path (str): the path to load existing model's parameters\n",
    "        steps_recurrent_loop_test (int): the number of recurrent step for testing (Phase I)\n",
    "        qaoa_optimizer (str): the optimizer for QAOA, ADAM or SGD\n",
    "        lr_qaoa (float): learning rate for QAOA optimizer\n",
    "        max_iter_qaoa (int): the max iteration for QAOA optimizer (Phase II)\n",
    "        conv_tol_qaoa (float): the convergence tolerance for QAOA optimizer\n",
    "        Results_save_path (str): the path to save results\n",
    "\"\"\"\n",
    "\n",
    "hyperparameter = {\n",
    "    'model_type': 'QK',             \n",
    "    'dataset_save_path': 'example_datasets.pkl', \n",
    "    'qaoa_layers': 2,\n",
    "    'lr_sequence': 8e-5,\n",
    "    'lr_mapping': 1e-4,\n",
    "    'epochs': 5,                     \n",
    "    'model_save_path': 'example', \n",
    "    'Results_save_path': 'example', \n",
    "    'mapping_type': 'Linear',\n",
    "    'layers': 1,\n",
    "    'input_feature_dim': 4,\n",
    "    'max_total_params': 4,\n",
    "    'loss_function_type': 'weighted',\n",
    "    'steps_recurrent_loop_train': 10,\n",
    "    'conv_tol_sequence': 1e-6,\n",
    "    'time_out': 600,\n",
    "    'continue_train': False,\n",
    "    'load_path': None,\n",
    "    'qaoa_optimizer': 'ADAM',\n",
    "    'lr_qaoa': 0.001,\n",
    "    'max_iter_qaoa': 300,\n",
    "    'conv_tol_qaoa': 1e-6,\n",
    "    'steps_recurrent_loop_test': 10,\n",
    "}\n",
    "\n",
    "args_namespace = Namespace(**hyperparameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets loaded from example_datasets.pkl\n",
      "Train = 180 samples, Val = 5 samples, Test = 5 samples\n",
      "\n",
      "--- Building and Training Model ---\n",
      "--- Model Summary ---\n",
      "L2L(\n",
      "  (sequence): QKLSTM(\n",
      "    (clayer_in): Linear(in_features=10, out_features=4, bias=True)\n",
      "    (clayer_out): Linear(in_features=4, out_features=5, bias=True)\n",
      "  )\n",
      "  (mapping): Linear(in_features=5, out_features=4, bias=True)\n",
      ")\n",
      "  QK Parameters: 69\n",
      "  Mapping Parameters: 24\n",
      "\n",
      "--- Training QK Model ---\n",
      "\n",
      "--- Starting QK Model Training ---\n",
      "Epoch 1/5\n",
      "Epoch 1 Mean loss: -5.31898271, Mean val loss:-14.71270263\n",
      "Current QK learning rate: 0.0000800000\n",
      "Current mapping learning rate: 0.0001000000\n",
      "Epoch 2/5\n",
      "Epoch 2 Mean loss: -5.62521532, Mean val loss:-15.15097500\n",
      "Current QK learning rate: 0.0000800000\n",
      "Current mapping learning rate: 0.0001000000\n",
      "Epoch 3/5\n",
      "Epoch 3 Mean loss: -5.72695843, Mean val loss:-15.28905832\n",
      "Current QK learning rate: 0.0000800000\n",
      "Current mapping learning rate: 0.0001000000\n",
      "Epoch 4/5\n",
      "Epoch 4 Mean loss: -5.75655125, Mean val loss:-15.31986436\n",
      "Current QK learning rate: 0.0000800000\n",
      "Current mapping learning rate: 0.0001000000\n",
      "Training stopped after 5/5\n",
      "mean loss:[np.float64(-5.318982708454132), np.float64(-5.6252153237660725), np.float64(-5.7269584271642895), np.float64(-5.756551247172886)]\n",
      "mean val loss:[-14.712702630521965, -15.150974998391742, -15.289058323359777, -15.319864364324303]\n",
      "mean loss:[np.float64(-5.318982708454132), np.float64(-5.6252153237660725), np.float64(-5.7269584271642895), np.float64(-5.756551247172886)]\n",
      "mean val loss:[-14.712702630521965, -15.150974998391742, -15.289058323359777, -15.319864364324303]\n",
      "Model saved successfully!\n",
      "\n",
      " Successfully loaded best model\n",
      "\n",
      "--- Evaluating Model ---\n",
      "\n",
      "--- Starting QK Model Testing ---\n",
      "\n",
      "--- Test Graph 5/5 (Nodes: 12, Edges: 37) ---\n",
      "QK predicted energies:[tensor([-0.2746,  0.7184,  0.1858, -0.0538]), tensor([-0.2771,  0.7983,  0.1997, -0.1256]), tensor([-0.2753,  0.8295,  0.2006, -0.1589]), tensor([-0.2733,  0.8424,  0.1988, -0.1754]), tensor([-0.2718,  0.8485,  0.1970, -0.1843]), tensor([-0.2709,  0.8518,  0.1958, -0.1894]), tensor([-0.2704,  0.8537,  0.1950, -0.1925]), tensor([-0.2701,  0.8550,  0.1946, -0.1944]), tensor([-0.2699,  0.8559,  0.1944, -0.1957]), tensor([-0.2699,  0.8565,  0.1943, -0.1965])]\n",
      "QK predicted params:-22.607933839843778\n",
      "\n",
      "--- QAOA optimization after model (Phase II) ---\n",
      "\n",
      "--- Starting QAOA Optimization ---\n",
      "Step = 50/300, Cost = -22.74809947\n",
      "Step = 100/300, Cost = -22.76753193\n",
      "Step = 150/300, Cost = -22.77381422\n",
      "Step = 200/300, Cost = -22.77581214\n",
      "Step = 250/300, Cost = -22.77627294\n",
      "  Convergence reached at step 284\n",
      "Optimization finished, final cost: -22.77634001\n",
      "\n",
      "--- Saving Complete ---\n"
     ]
    }
   ],
   "source": [
    "exp_L2L.run_experiment(args_namespace)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qa-qaoa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
