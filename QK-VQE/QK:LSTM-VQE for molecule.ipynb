{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM/QK-VQE\n",
    "Overview\n",
    "- calss molecule_data: prepare molecule dataset and pre-processing\n",
    "- class VQE: build VQE\n",
    "- calss VQEOptimizer: VQE optimization\n",
    "- class LSTM: build model\n",
    "- calss ModelTrain: train and evaluate model\n",
    "\n",
    "Need to Debug\n",
    "1. test for different molecule (standard VQE)\n",
    "2. optuna might run for 2-3 hr\n",
    "3. early convergence in training: dataset size, torch.optim.lr_scheduler.ReduceLROnPlateau\n",
    "4. FIM approximate\n",
    "5. val set\n",
    "6. Gauss. encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## My module\n",
    "import molecule_data\n",
    "import VQE\n",
    "import QKLSTM\n",
    "import Model\n",
    "## basis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "## random\n",
    "import random\n",
    "import math\n",
    "from typing import List, Callable, Tuple\n",
    "## ML\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim \n",
    "from scipy.optimize import minimize\n",
    "## QML\n",
    "import h5py\n",
    "import pennylane as qml\n",
    "from pennylane import qchem\n",
    "## access file \n",
    "import os \n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "qml.math.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vqe_params(molecule_data):\n",
    "        electrons = sum(molecule_data.hf_state)\n",
    "        orbitals = len(molecule_data.hf_state)\n",
    "\n",
    "        single, double = qchem.excitations(electrons, orbitals)\n",
    "        s_w, d_w = qml.qchem.excitations_to_wires(single, double)\n",
    "        num_single = len(s_w)\n",
    "        num_double = len(d_w)\n",
    "        return num_single+num_double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---Hyperparameters ---\n",
    "## LSTM\n",
    "### opt for LSTM train: Adam\n",
    "model_type = \"QK\" #LSTM or OK\n",
    "mapping_type = \"Linear\" # Linear or DNN\n",
    "fixed_param_dim = 30\n",
    "lr_lstm = 0.001\n",
    "lr_mapping = 0.001\n",
    "epochs = 5\n",
    "#steps_per_epoch = 10\n",
    "conv_tol_lstm = 1e-5\n",
    "loss_type = \"observed improvement\" # weighted or observed improvement\n",
    "steps_recurrent_loop_train = 5 # for train (steps_per_epoch)\n",
    "steps_recurrent_loop_test = 10 # for test\n",
    "\n",
    "## VQE\n",
    "lr_vqe = 0.01\n",
    "max_iter_vqe = 500\n",
    "conv_tol_vqe = 1e-6\n",
    "vqe_optimizer = \"ADAM\"\n",
    "\n",
    "# Data set\n",
    "molecule = [\n",
    "        (\"H2\", [0.5]),\n",
    "        (\"H2\", [0.54]),\n",
    "        (\"H2\", [0.58]),\n",
    "        (\"H2\", [0.62]),\n",
    "        (\"H2\", [0.66]),\n",
    "        (\"H2\", [0.82]),\n",
    "        (\"H2\", [0.86]),\n",
    "        (\"H2\", [0.9]),\n",
    "        (\"H2\", [0.94]),\n",
    "        (\"H2\", [0.98]),\n",
    "        (\"H2\", [1.02]),\n",
    "        (\"H2\", [1.06]),\n",
    "        (\"H2\", [1.1]),\n",
    "        (\"H2\", [1.14]),\n",
    "        (\"H2\", [1.18]),\n",
    "        (\"H2\", [1.22]),\n",
    "        (\"H2\", [1.26]),\n",
    "        (\"H2\", [1.3]),\n",
    "        (\"H2\", [1.34]),\n",
    "        (\"H2\", [1.38]),\n",
    "        (\"H2\", [1.42]),\n",
    "        (\"H2\", [1.46]),\n",
    "        (\"H2\", [1.5]),\n",
    "        (\"H2\", [1.54]),\n",
    "        (\"H2\", [1.58]),\n",
    "        (\"H2\", [1.62]),\n",
    "        (\"H2\", [1.66]),\n",
    "        (\"H2\", [1.7]),\n",
    "        (\"H2\", [1.74]),\n",
    "        (\"H2\", [1.78]),\n",
    "        (\"H2\", [1.82]),\n",
    "        (\"H2\", [1.86]),\n",
    "        (\"H2\", [1.9]),\n",
    "        (\"H2\", [1.94]),\n",
    "        (\"H2\", [1.98]),\n",
    "        (\"H2\", [2.02]),\n",
    "        (\"H2\", [2.06]),\n",
    "        (\"H2\", [2.1]),\n",
    "        (\"H3+\", [0.5]),\n",
    "        (\"H3+\", [0.54]),\n",
    "        (\"H3+\", [0.58]),\n",
    "        (\"H3+\", [0.62]),\n",
    "        (\"H3+\", [0.66]),\n",
    "        (\"H3+\", [0.7]),\n",
    "        (\"H3+\", [0.74]),\n",
    "        (\"H3+\", [0.78]),\n",
    "        (\"H3+\", [0.82]),\n",
    "        (\"H3+\", [0.86]),\n",
    "        (\"H3+\", [0.9]),\n",
    "        (\"H3+\", [0.94]),\n",
    "        (\"H3+\", [0.98]),\n",
    "        (\"H3+\", [1.02]),\n",
    "        (\"H3+\", [1.06]),\n",
    "        (\"H3+\", [1.1]),\n",
    "        (\"H3+\", [1.26]),\n",
    "        (\"H3+\", [1.3]),\n",
    "        (\"H3+\", [1.34]),\n",
    "        (\"H3+\", [1.38]),\n",
    "        (\"H3+\", [1.42]),\n",
    "        (\"H3+\", [1.46]),\n",
    "        (\"H3+\", [1.5]),\n",
    "        (\"H3+\", [1.54]),\n",
    "        (\"H3+\", [0.5]),\n",
    "        (\"H2\", None),\n",
    "        (\"H3+\", None),\n",
    "        (\"H4\", None)\n",
    "        ]\n",
    "\n",
    "train_split_index = 65\n",
    "# Save File Path\n",
    "Data_save_path = \"./datasets2/\"\n",
    "Model_save_path = \"model_test2_params\"\n",
    "Results_save_path = \"model_test2_result\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Load Data ---\n",
      "\n",
      "--- Complete Load Data ---\n",
      "                                                   0\n",
      "0  <Dataset = molname: H2, basis: STO-3G, bondlen...\n",
      "Train set[<Dataset = molname: H2, basis: STO-3G, bondlength: 0.742, attributes: ['molname', 'basis', ...]>]\n",
      "Test set[]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Prepare Dataset\n",
    "\"\"\"\n",
    "# load data from pennylane dataset if you have no data\n",
    "dataset = molecule_data.molecule_data.load_data(molecule, basis = \"STO-3G\", folder_path = Data_save_path)\n",
    "# If you have data in your computer, then\n",
    "# I don't know\n",
    "max_qubits, max_s_params, max_d_params, max_params, train_set, test_set = molecule_data.molecule_data.data_params(df = dataset, train_split_index = train_split_index)\n",
    "print(f\"Train set{train_set}\")\n",
    "print(f\"Test set{test_set}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define model and train\n",
    "\"\"\"\n",
    "# --- Model Training ---\n",
    "## define model\n",
    "beta_model = Model.LSTM(model_type = model_type,\n",
    "                      mapping_type= mapping_type,\n",
    "                       input_feature_dim = fixed_param_dim,\n",
    "                       max_total_params = max_params,\n",
    "                       max_qubits = max_qubits,\n",
    "                       loss_function_type = loss_type,\n",
    "                        max_s_params = max_s_params,\n",
    "                        max_d_params = max_d_params\n",
    "                        )\n",
    "    \n",
    "print(f\"--- Model Summary ---\")\n",
    "print(beta_model)\n",
    "lstm_params = sum(p.numel() for p in beta_model.lstm.parameters())\n",
    "print(f\"  {model_type} Parameters: {lstm_params}\")\n",
    "mapping_params = sum(p.numel() for p in beta_model.mapping.parameters())\n",
    "print(f\"  Mapping Parameters: {mapping_params}\")\n",
    "\n",
    "trainer = Model.ModelTrain(beta_model,\n",
    "                         lr_lstm = lr_lstm,\n",
    "                         lr_mapping= lr_mapping,\n",
    "                         num_rnn_iteration = steps_recurrent_loop_train)\n",
    "\n",
    "print(f\"\\n--- Training {model_type} Model ---\")\n",
    "\n",
    "trainer.train(train_set,\n",
    "                  epochs = epochs,\n",
    "                  conv_tol_lstm = conv_tol_lstm)\n",
    "\n",
    "torch.save(beta_model.state_dict(), f\"{Model_save_path}_{model_type}_{loss_type}.pth\")\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model Testing\n",
    "\"\"\"\n",
    "# --- Model Evaluating ---\n",
    "print(f\"\\n--- Evaluating {model_type} Model ---\")\n",
    "\n",
    "\n",
    "for i, molecule_data in enumerate(test_set):\n",
    "        molecule_test_result = {}\n",
    "        # predicted by model\n",
    "        #molecule_cost = VQE(molecule_data, max_qubits, True) #max_s_params\n",
    "        #loss_qnode = molecule_cost.get_loss_function()\n",
    "        predicted_params_list, predicted_energies_list = trainer.evaluate(\n",
    "            molecule_data = molecule_data,\n",
    "            num_rnn_iteration = steps_recurrent_loop_test)\n",
    "\n",
    "        print(f\"the test molecule:{molecule_data.molname}, bondlength: {molecule_data.bondlength}\")\n",
    "        print(f\"{model_type} predicted energies:{predicted_energies_list}\")\n",
    "\n",
    "        # use LSTM/QK -FC output as initial params for VQE to optimize\n",
    "        print(f\"\\n--- VQE optimization after model ---\")\n",
    "        print(f\"the test molecule:{molecule_data.molname}, bondlength: {molecule_data.bondlength}\")\n",
    "        test_vqe = VQE.VQE(molecule_data, max_qubits, True) #max_s_params\n",
    "        opt_lstm_vqe = VQE.VQEOptimizer(test_vqe)\n",
    "        conv_iter_lstm, final_params_lstm, final_energy_lstm, params_history_lstm, energy_history_lstm = opt_lstm_vqe.run_optimization(\n",
    "            initial_params = predicted_params_list[-1],\n",
    "            optimizer = vqe_optimizer,\n",
    "            max_iter = max_iter_vqe,\n",
    "            learning_rate = lr_vqe,\n",
    "            conv_tol = conv_tol_vqe\n",
    "            )\n",
    "        \n",
    "        vqe_params_test = vqe_params(molecule_data)\n",
    "        \n",
    "        # VQE predict without guess by LSTM/QK\n",
    "        print(f\"\\n--- Standard VQE, random params ---\")\n",
    "        print(f\"the test molecule:{molecule_data.molname}, bondlength: {molecule_data.bondlength}\")\n",
    "        # random params\n",
    "        params_rand = torch.rand(max_params, dtype = torch.float32)\n",
    "        vqe_test_rand = VQE.VQE(molecule_data, max_qubits, False)\n",
    "        opt_rand_vqe = VQE.VQEOptimizer(vqe_test_rand)\n",
    "        conv_iter_rand, final_params_rand, final_energy_rand, params_history_rand, energy_history_rand = opt_rand_vqe.run_optimization(\n",
    "            initial_params = params_rand,\n",
    "            optimizer = vqe_optimizer,\n",
    "            max_iter = max_iter_vqe,\n",
    "            learning_rate = lr_vqe,\n",
    "            conv_tol = conv_tol_vqe\n",
    "            )\n",
    "\n",
    "        # params which all zeros\n",
    "        print(f\"\\n--- Standard VQE, zero params ---\")\n",
    "        print(f\"the test molecule:{molecule_data.molname}, bondlength: {molecule_data.bondlength}\")\n",
    "        params_zeros = torch.zeros(max_params, dtype = torch.float32)\n",
    "        vqe_test_zeros = VQE.VQE(molecule_data, max_qubits, False)\n",
    "        opt_zeros_vqe = VQE.VQEOptimizer(vqe_test_zeros)\n",
    "        conv_iter_zeros, final_params_zeros, final_energy_zeros, params_history_zeros, energy_history_zeros = opt_zeros_vqe.run_optimization(\n",
    "            initial_params = params_zeros,\n",
    "            optimizer = vqe_optimizer,\n",
    "            max_iter = max_iter_vqe,\n",
    "            learning_rate = lr_vqe,\n",
    "            conv_tol = conv_tol_vqe\n",
    "            )\n",
    "        \"\"\"\"\"\n",
    "        print(f\"\\n--- Standard VQE, pi params ---\")\n",
    "        print(f\"the test molecule:{molecule_data.molname}, bondlength: {molecule_data.bondlength}\")\n",
    "        params_pi = torch.ones(max_params,dtype = torch.float32) * math.pi\n",
    "        vqe_test_pi = VQE.VQE(molecule_data, max_qubits, False)\n",
    "        opt_pi_vqe = VQE.VQEOptimizer(vqe_test_pi)\n",
    "        conv_iter_pi, final_params_pi , final_energy_pi , params_history_pi , energy_history_pi  = opt_pi_vqe.run_optimization(\n",
    "            initial_params = params_pi,\n",
    "            optimizer = vqe_optimizer,\n",
    "            max_iter = max_iter_vqe,\n",
    "            learning_rate = lr_vqe,\n",
    "            conv_tol = conv_tol_vqe\n",
    "            )\n",
    "        \"\"\"\n",
    "        # save result and output as csv\n",
    "        # result to pd\n",
    "        molecule_test_result = {\n",
    "            #'molecule': molecule_data.molname,\n",
    "            #'bondlength': molecule_data.bondlength,\n",
    "            'LSTM-VQE': pd.Series(predicted_energies_list),\n",
    "            'VQE after LSTM':pd.Series(energy_history_lstm),\n",
    "            'VQE Random': pd.Series(energy_history_rand),\n",
    "            'VQE Zeros': pd.Series(energy_history_zeros),\n",
    "            #'VQE Pi': pd.Series(energy_history_pi)\n",
    "            }\n",
    "        \n",
    "        df_result = pd.DataFrame(molecule_test_result)\n",
    "        df_result.to_csv(f\"{Results_save_path}_{model_type}_{loss_type}_{molecule_data.molname}_{molecule_data.bondlength}.csv\", index = False)\n",
    "        print(\"\\n--- Saving Complete ---\")\n",
    "\n",
    "        print(\"Result of VQE Optimization\")\n",
    "        E_fci = test_set[i].fci_energy\n",
    "        #plt.figure(figsize = (20,10))\n",
    "        plt.plot(range(1, len(predicted_energies_list) + 1), predicted_energies_list, marker='o', label=f'{model_type}-VQE', ls=\"dashed\")\n",
    "        plt.plot(range(1, len(energy_history_lstm) + 1), energy_history_lstm, marker='o', label=f'VQE after {model_type}', ls=\"dashed\")\n",
    "        plt.plot(range(1, len(energy_history_rand) + 1), energy_history_rand, marker='o', label='VQE, Random', ls=\"dashed\")\n",
    "        plt.plot(range(1, len(energy_history_zeros) + 1), energy_history_zeros, marker='o', label='VQE, Zeros', ls=\"dashed\")\n",
    "        #plt.plot(range(1, len(energy_history_pi) + 1), energy_history_pi, marker='o', label='VQE, Pi', ls=\"dashed\")\n",
    "        plt.plot(range(1, len(energy_history_rand) + 1), np.full(len(energy_history_rand) , E_fci), color=\"red\")\n",
    "        plt.xlabel(\"Optimization step\")\n",
    "        plt.ylabel(\"Energy (Hartree)\")\n",
    "        plt.title(f\"VQE Optimization Comparison, Test = {molecule_data.molname}, {molecule_data.bondlength}\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Result of Erros\")\n",
    "        #plt.figure(figsize = (20,10))\n",
    "        plt.plot(range(1, len(predicted_energies_list) + 1), [item-E_fci for item in predicted_energies_list], marker='o', label=f'{model_type}-VQE', ls=\"dashed\")\n",
    "        plt.plot(range(1, len(energy_history_lstm) + 1), [item-E_fci for item in energy_history_lstm], marker='o', label=f'VQE after {model_type}', ls=\"dashed\")\n",
    "        plt.plot(range(1, len(energy_history_zeros) + 1), [item-E_fci for item in energy_history_zeros], marker='o', label='VQE, Zeros', ls=\"dashed\")\n",
    "        plt.plot(range(1, len(energy_history_lstm) + 1), np.full(len(energy_history_lstm) , 0.0016), color=\"red\")\n",
    "        plt.xlabel(\"Optimization step\")\n",
    "        plt.ylabel(\"Energy Error (Hartree)\")\n",
    "        plt.title(f\"VQE Optimization Error Comparison, Test = {molecule_data.molname}, {molecule_data.bondlength}\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "print(\"\\n--- Simulation Complete ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
